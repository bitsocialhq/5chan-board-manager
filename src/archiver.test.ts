import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest'
import { mkdtempSync, rmSync } from 'node:fs'
import { join } from 'node:path'
import { tmpdir } from 'node:os'
import { loadState, saveState } from './state.js'
import type { ArchiverState, PlebbitInstance, Page, ThreadComment } from './types.js'

// Helper to create a mock thread
function mockThread(cid: string, overrides: Record<string, unknown> = {}): ThreadComment {
  return { cid, pinned: false, locked: false, replyCount: 0, ...overrides } as unknown as ThreadComment
}

interface MockModerationRecord {
  commentCid: string
  commentModeration: { locked?: boolean; purged?: boolean }
  subplebbitAddress: string
  signer: { address: string; privateKey: string; type: 'ed25519' }
}

// Helper to create a mock plebbit instance
function createMockPlebbit(dataPath: string) {
  const mockSigner = { address: 'mock-address-123', privateKey: 'mock-pk-123' }
  const publishedModerations: MockModerationRecord[] = []

  return {
    instance: {
      dataPath,
      createSigner: vi.fn().mockResolvedValue({ ...mockSigner }),
      getSubplebbit: vi.fn(),
      createCommentModeration: vi.fn().mockImplementation((opts: MockModerationRecord) => ({
        ...opts,
        publish: vi.fn().mockImplementation(async () => {
          publishedModerations.push(opts)
        }),
      })),
    } as unknown as PlebbitInstance,
    mockSigner,
    publishedModerations,
  }
}

// Helper to create a mock subplebbit with posts configuration
function createMockSubplebbit(postsConfig: {
  pageCids?: Partial<Record<string, string>>
  pages?: Partial<Record<string, Page>>
  getPage?: (args: { cid: string }) => Promise<Page>
}) {
  let updateCallback: (() => void) | undefined
  return {
    roles: { 'mock-address-123': { role: 'moderator' as const } },
    posts: {
      pageCids: postsConfig.pageCids ?? {},
      pages: postsConfig.pages ?? {},
      getPage: postsConfig.getPage ?? vi.fn(),
    },
    on: vi.fn().mockImplementation((event: string, cb: () => void) => {
      if (event === 'update') updateCallback = cb
    }),
    update: vi.fn().mockImplementation(async () => {
      updateCallback?.()
    }),
    edit: vi.fn().mockResolvedValue(undefined),
    stop: vi.fn().mockResolvedValue(undefined),
    removeListener: vi.fn(),
    // expose for tests to trigger update events manually
    _triggerUpdate: () => updateCallback?.(),
  }
}

describe('archiver logic', () => {
  let dir: string
  let statePath: string

  beforeEach(() => {
    dir = mkdtempSync(join(tmpdir(), 'archiver-test-'))
    statePath = join(dir, '5chan-archiver-state.json')
  })

  afterEach(() => {
    rmSync(dir, { recursive: true, force: true })
  })

  describe('state-based thread tracking', () => {
    it('records lockTimestamp when adding a locked thread', () => {
      const state: ArchiverState = { signers: {}, lockedThreads: {} }
      const now = Math.floor(Date.now() / 1000)
      state.lockedThreads['QmTest'] = { lockTimestamp: now }
      saveState(statePath, state)

      const loaded = loadState(statePath)
      expect(loaded.lockedThreads['QmTest'].lockTimestamp).toBe(now)
    })

    it('removes thread from state on purge', () => {
      const state: ArchiverState = {
        signers: {},
        lockedThreads: {
          'QmKeep': { lockTimestamp: 1000 },
          'QmPurge': { lockTimestamp: 500 },
        },
      }
      delete state.lockedThreads['QmPurge']
      saveState(statePath, state)

      const loaded = loadState(statePath)
      expect(loaded.lockedThreads['QmKeep']).toBeDefined()
      expect(loaded.lockedThreads['QmPurge']).toBeUndefined()
    })
  })

  describe('thread filtering', () => {
    it('filters out pinned threads', () => {
      const threads = [
        mockThread('Qm1', { pinned: true }),
        mockThread('Qm2'),
        mockThread('Qm3'),
        mockThread('Qm4', { pinned: true }),
      ]
      const nonPinned = threads.filter((t) => !t.pinned)
      expect(nonPinned).toHaveLength(2)
      expect(nonPinned.map((t) => t.cid)).toEqual(['Qm2', 'Qm3'])
    })

    it('identifies threads beyond capacity', () => {
      const perPage = 2
      const pages = 2
      const maxThreads = perPage * pages // 4

      const threads = Array.from({ length: 6 }, (_, i) => mockThread(`Qm${i}`))
      const nonPinned = threads.filter((t) => !t.pinned)
      const beyondCapacity = nonPinned.slice(maxThreads)

      expect(beyondCapacity).toHaveLength(2)
      expect(beyondCapacity.map((t) => t.cid)).toEqual(['Qm4', 'Qm5'])
    })

    it('skips already locked threads', () => {
      const threads = [
        mockThread('Qm1'),
        mockThread('Qm2'),
        mockThread('Qm3', { locked: true }),
        mockThread('Qm4'),
        mockThread('Qm5'),
      ]
      const maxThreads = 2
      const nonPinned = threads.filter((t) => !t.pinned)
      const beyondCapacity = nonPinned.slice(maxThreads)
      const toLock = beyondCapacity.filter((t) => !t.locked)

      expect(toLock).toHaveLength(2)
      expect(toLock.map((t) => t.cid)).toEqual(['Qm4', 'Qm5'])
    })
  })

  describe('bump limit detection', () => {
    it('identifies threads at or above bump limit', () => {
      const bumpLimit = 300
      const threads = [
        mockThread('Qm1', { replyCount: 100 }),
        mockThread('Qm2', { replyCount: 300 }),
        mockThread('Qm3', { replyCount: 500 }),
        mockThread('Qm4', { replyCount: 299 }),
      ]
      const atBumpLimit = threads.filter((t) => t.replyCount >= bumpLimit)
      expect(atBumpLimit.map((t) => t.cid)).toEqual(['Qm2', 'Qm3'])
    })

    it('skips locked threads when checking bump limit', () => {
      const bumpLimit = 300
      const threads = [
        mockThread('Qm1', { replyCount: 300, locked: true }),
        mockThread('Qm2', { replyCount: 400 }),
      ]
      const toLock = threads.filter((t) => t.replyCount >= bumpLimit && !t.locked)
      expect(toLock).toHaveLength(1)
      expect(toLock[0].cid).toBe('Qm2')
    })
  })

  describe('purge timing', () => {
    it('identifies threads past archive_purge_seconds', () => {
      const archivePurgeSeconds = 172800 // 48h
      const now = Math.floor(Date.now() / 1000)
      const state: ArchiverState = {
        signers: {},
        lockedThreads: {
          'QmOld': { lockTimestamp: now - 200000 }, // > 48h ago
          'QmRecent': { lockTimestamp: now - 1000 }, // < 48h ago
          'QmExact': { lockTimestamp: now - 172800 }, // exactly 48h ago
        },
      }

      const toPurge = Object.entries(state.lockedThreads)
        .filter(([_, info]) => now - info.lockTimestamp > archivePurgeSeconds)
      // "QmExact" is exactly at the boundary (not >), so only QmOld
      expect(toPurge.map(([cid]) => cid)).toEqual(['QmOld'])
    })

    it('does not purge threads locked less than archive_purge_seconds ago', () => {
      const archivePurgeSeconds = 172800
      const now = Math.floor(Date.now() / 1000)
      const state: ArchiverState = {
        signers: {},
        lockedThreads: {
          'Qm1': { lockTimestamp: now - 100 },
          'Qm2': { lockTimestamp: now },
        },
      }

      const toPurge = Object.entries(state.lockedThreads)
        .filter(([_, info]) => now - info.lockTimestamp > archivePurgeSeconds)
      expect(toPurge).toHaveLength(0)
    })
  })

  describe('signer management', () => {
    it('persists signer to state file', () => {
      const state: ArchiverState = { signers: {}, lockedThreads: {} }
      state.signers['my-board.eth'] = { privateKey: 'test-private-key' }
      saveState(statePath, state)

      const loaded = loadState(statePath)
      expect(loaded.signers['my-board.eth'].privateKey).toBe('test-private-key')
    })

    it('retrieves existing signer from state', () => {
      const state: ArchiverState = {
        signers: { 'board.eth': { privateKey: 'existing-key' } },
        lockedThreads: {},
      }
      saveState(statePath, state)

      const loaded = loadState(statePath)
      expect(loaded.signers['board.eth']).toBeDefined()
      expect(loaded.signers['board.eth'].privateKey).toBe('existing-key')
    })

    it('handles multiple signers for different subplebbits', () => {
      const state: ArchiverState = {
        signers: {
          'board1.eth': { privateKey: 'key1' },
          'board2.eth': { privateKey: 'key2' },
        },
        lockedThreads: {},
      }
      saveState(statePath, state)

      const loaded = loadState(statePath)
      expect(Object.keys(loaded.signers)).toHaveLength(2)
      expect(loaded.signers['board1.eth'].privateKey).toBe('key1')
      expect(loaded.signers['board2.eth'].privateKey).toBe('key2')
    })
  })

  describe('idempotency', () => {
    it('skips threads already tracked in lockedThreads state', () => {
      const state: ArchiverState = {
        signers: {},
        lockedThreads: { 'QmAlready': { lockTimestamp: 1000 } },
      }
      const threads = [mockThread('QmAlready'), mockThread('QmNew')]
      const maxThreads = 0 // all beyond capacity

      const nonPinned = threads.filter((t) => !t.pinned)
      const beyondCapacity = nonPinned.slice(maxThreads)
      const toLock = beyondCapacity.filter((t) => !t.locked && !state.lockedThreads[t.cid])

      expect(toLock).toHaveLength(1)
      expect(toLock[0].cid).toBe('QmNew')
    })
  })

  describe('cold start', () => {
    it('handles many threads needing lock at once', () => {
      const perPage = 2
      const pages = 1
      const maxThreads = perPage * pages // 2

      // Simulate 50 threads on a board that's been running without archiver
      const threads = Array.from({ length: 50 }, (_, i) => mockThread(`Qm${i}`))
      const nonPinned = threads.filter((t) => !t.pinned)
      const beyondCapacity = nonPinned.slice(maxThreads)
      const toLock = beyondCapacity.filter((t) => !t.locked)

      expect(toLock).toHaveLength(48)
    })
  })

  describe('createCommentModeration mock', () => {
    it('creates lock moderation with correct shape', async () => {
      const { instance } = createMockPlebbit(dir)
      const mod = await instance.createCommentModeration({
        commentCid: 'QmTest',
        commentModeration: { locked: true },
        subplebbitAddress: 'board.eth',
        signer: { address: 'addr', privateKey: 'pk', type: 'ed25519' },
      })
      expect(instance.createCommentModeration).toHaveBeenCalledWith({
        commentCid: 'QmTest',
        commentModeration: { locked: true },
        subplebbitAddress: 'board.eth',
        signer: { address: 'addr', privateKey: 'pk', type: 'ed25519' },
      })
      expect(mod.publish).toBeDefined()
    })

    it('creates purge moderation with correct shape', async () => {
      const { instance } = createMockPlebbit(dir)
      const mod = await instance.createCommentModeration({
        commentCid: 'QmTest',
        commentModeration: { purged: true },
        subplebbitAddress: 'board.eth',
        signer: { address: 'addr', privateKey: 'pk', type: 'ed25519' },
      })
      expect(mod.commentModeration.purged).toBe(true)
    })

    it('tracks published moderations', async () => {
      const { instance, publishedModerations } = createMockPlebbit(dir)
      const mod = await instance.createCommentModeration({
        commentCid: 'QmTest',
        commentModeration: { locked: true },
        subplebbitAddress: 'board.eth',
        signer: { address: 'addr', privateKey: 'pk', type: 'ed25519' },
      })
      await mod.publish()
      expect(publishedModerations).toHaveLength(1)
      expect(publishedModerations[0].commentCid).toBe('QmTest')
    })
  })

  describe('thread fetching scenarios', () => {
    it('returns early when subplebbit has no posts', async () => {
      const { instance, publishedModerations } = createMockPlebbit(dir)
      const mockSub = createMockSubplebbit({
        pageCids: {},
        pages: {},
      })
      vi.mocked(instance.getSubplebbit).mockResolvedValue(mockSub as unknown as Awaited<ReturnType<PlebbitInstance['getSubplebbit']>>)

      const { startArchiver } = await import('./archiver.js')
      const archiver = startArchiver({
        subplebbitAddress: 'board.eth',
        plebbit: instance,
        perPage: 15,
        pages: 10,
      })

      // Wait for startup + update event to fire
      await vi.waitFor(() => {
        expect(mockSub.update).toHaveBeenCalled()
      })

      // No moderations should have been published
      expect(publishedModerations).toHaveLength(0)
      await archiver.stop()
    })

    it('fetches all threads via pageCids.active with single page', async () => {
      const { instance, publishedModerations } = createMockPlebbit(dir)
      const threadsOnPage = Array.from({ length: 5 }, (_, i) => mockThread(`QmActive${i}`))
      const getPage = vi.fn().mockResolvedValue({
        comments: threadsOnPage,
        nextCid: undefined,
      } as Page)

      const mockSub = createMockSubplebbit({
        pageCids: { active: 'QmActivePage1' },
        pages: {},
        getPage,
      })
      vi.mocked(instance.getSubplebbit).mockResolvedValue(mockSub as unknown as Awaited<ReturnType<PlebbitInstance['getSubplebbit']>>)

      const { startArchiver } = await import('./archiver.js')
      const archiver = startArchiver({
        subplebbitAddress: 'board.eth',
        plebbit: instance,
        perPage: 2,
        pages: 1, // capacity = 2, so 3 threads should get locked
      })

      await vi.waitFor(() => {
        expect(getPage).toHaveBeenCalledWith({ cid: 'QmActivePage1' })
      })

      // Wait for moderations to be published (3 threads beyond capacity of 2)
      await vi.waitFor(() => {
        expect(publishedModerations).toHaveLength(3)
      })

      const lockedCids = publishedModerations.map((m) => m.commentCid)
      expect(lockedCids).toEqual(['QmActive2', 'QmActive3', 'QmActive4'])
      await archiver.stop()
    })

    it('paginates via nextCid when multiple pages exist', async () => {
      const { instance, publishedModerations } = createMockPlebbit(dir)
      const page1Threads = [mockThread('QmP1a'), mockThread('QmP1b')]
      const page2Threads = [mockThread('QmP2a'), mockThread('QmP2b')]

      const getPage = vi.fn()
        .mockResolvedValueOnce({ comments: page1Threads, nextCid: 'QmPage2Cid' } as Page)
        .mockResolvedValueOnce({ comments: page2Threads, nextCid: undefined } as Page)

      const mockSub = createMockSubplebbit({
        pageCids: { active: 'QmPage1Cid' },
        pages: {},
        getPage,
      })
      vi.mocked(instance.getSubplebbit).mockResolvedValue(mockSub as unknown as Awaited<ReturnType<PlebbitInstance['getSubplebbit']>>)

      const { startArchiver } = await import('./archiver.js')
      const archiver = startArchiver({
        subplebbitAddress: 'board.eth',
        plebbit: instance,
        perPage: 1,
        pages: 1, // capacity = 1, so 3 threads should get locked
      })

      await vi.waitFor(() => {
        expect(getPage).toHaveBeenCalledTimes(2)
      })

      // Verify both pages were fetched with correct CIDs
      expect(getPage).toHaveBeenCalledWith({ cid: 'QmPage1Cid' })
      expect(getPage).toHaveBeenCalledWith({ cid: 'QmPage2Cid' })

      // 4 total threads, capacity 1 â†’ 3 locked
      await vi.waitFor(() => {
        expect(publishedModerations).toHaveLength(3)
      })

      const lockedCids = publishedModerations.map((m) => m.commentCid)
      expect(lockedCids).toEqual(['QmP1b', 'QmP2a', 'QmP2b'])
      await archiver.stop()
    })

    it('falls back to preloaded hot page when pageCids.active is absent', async () => {
      const { instance, publishedModerations } = createMockPlebbit(dir)
      const hotThreads = Array.from({ length: 4 }, (_, i) => mockThread(`QmHot${i}`))

      const mockSub = createMockSubplebbit({
        pageCids: {}, // no active pageCid
        pages: {
          hot: { comments: hotThreads, nextCid: undefined } as Page,
        },
      })
      vi.mocked(instance.getSubplebbit).mockResolvedValue(mockSub as unknown as Awaited<ReturnType<PlebbitInstance['getSubplebbit']>>)

      const { startArchiver } = await import('./archiver.js')
      const archiver = startArchiver({
        subplebbitAddress: 'board.eth',
        plebbit: instance,
        perPage: 1,
        pages: 2, // capacity = 2, so 2 threads should get locked
      })

      await vi.waitFor(() => {
        expect(mockSub.update).toHaveBeenCalled()
      })

      await vi.waitFor(() => {
        expect(publishedModerations).toHaveLength(2)
      })

      const lockedCids = publishedModerations.map((m) => m.commentCid)
      expect(lockedCids).toEqual(['QmHot2', 'QmHot3'])
      await archiver.stop()
    })
  })
})
